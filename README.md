# Configurable GenAI Chatbot Pipeline

A modular, configurable GenAI chatbot pipeline demonstrating foundational GenAI concepts. This project performs end-to-end retrieval-augmented generation (RAG) from data loading to generating responses via LLMs, with support for multiple vector stores and embedding models, using `.txt` and `.pdf` documents as knowledge sources.

---

## ğŸ” Project Overview

This project is designed to showcase core GenAI and RAG concepts in a clean, maintainable pipeline-based architecture. Each pipeline component is modularized for specific responsibilities, and all steps are logged for transparency. Configuration flexibility is achieved using a central `config.yaml` file, allowing users to switch between vector stores, LLMs, embeddings, and data formats without changing core logic.

---

## ğŸ’¡ Motivation

The goal was to move beyond notebooks and implement GenAI functionality in a scalable, extensible codebase using modern engineering practicesâ€”modularity, logging, configuration, and environment management.

---

## âš™ï¸ Pipeline Architecture

```text
main.py
â”‚
â”œâ”€â”€ config_loader.py         â†’ Loads config.yaml
â”œâ”€â”€ data_loader.py           â†’ Loads data (.txt/.pdf)
â”œâ”€â”€ data_splitter.py         â†’ Splits data using RCTSplitter
â”œâ”€â”€ embedder.py              â†’ Creates embedding model object
â”œâ”€â”€ vectordb_builder.py      â†’ Builds FAISS/Chroma vector DB and returns retriever
â”œâ”€â”€ prompt_builder.py        â†’ Builds prompt and retrieval chain
â”œâ”€â”€ run_retriever_chain.py   â†’ Executes the LLM with user query
â””â”€â”€ app.py                   â†’ Streamlit app for querying (separate from pipeline)
```

---

## ğŸš€ Features

* ğŸ“„ **Supports `.txt` and `.pdf`** data formats
* ğŸ§  **Local Ollama LLMs and embedding models** supported
* ğŸ—ƒï¸ **FAISS and Chroma** vector database options
* âš™ï¸ **Flexible configuration** via `config.yaml`
* ğŸ“¦ **Fully modular architecture** with component-level logging
* ğŸŒ **Simple Streamlit UI** for user interaction
* ğŸ“ **Data credit** to [Stanford Encyclopedia of Philosophy (SEP)](https://plato.stanford.edu/entries/critical-thinking)

---

## ğŸ§° Tech Stack

* [LangChain](https://github.com/langchain-ai/langchain)
* [Ollama](https://ollama.com/)
* [FAISS CPU](https://github.com/facebookresearch/faiss)
* [ChromaDB](https://www.trychroma.com/)
* [Streamlit](https://streamlit.io/)
* [PyPDF](https://pypi.org/project/pypdf/)

---

## ğŸ› ï¸ Getting Started

```bash
# Clone repo
git clone <your-repo-url>
cd your-project

# Create virtual env and install dependencies
python -m venv venv
venv\Scripts\activate   # or source venv/bin/activate on Linux
pip install -r requirements.txt

# Edit these paths manually in:
# src/config_loader.py â†’ path to config.yaml
# src/logger.py        â†’ path for logs
# src/vectordb_builder.py â†’ output folders for FAISS/Chroma
```

---

## ğŸ—‚ï¸ Project Structure

```
project/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ text_data.txt
â”‚   â””â”€â”€ pdf_data.pdf
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ pipeline_logs.log
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config_loader.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ data_splitter.py
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ prompt_builder.py
â”‚   â”œâ”€â”€ run_retriever_chain.py
â”‚   â””â”€â”€ vectordb_builder.py
â”œâ”€â”€ vector_store_dbs/
â”‚   â”œâ”€â”€ faiss_vecdb/
â”‚   â””â”€â”€ chroma_vecdb/
â”œâ”€â”€ app.py
â”œâ”€â”€ app_working.png
â”œâ”€â”€ main.py
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Configuration (`config.yaml`)

```yaml
data_file:
  data_file_path: "data/text_data.txt"

revursive_text_splitter:
  chunk_size: 300
  chunk_overlap: 60

ollama_embedding:
  embedding_model: "mxbai-embed-large:335m"

ollama_model:
  ollama_llm: "gemma3:1b"

vector_store_db: faiss

chatprompttemplate_system_instruction: >
  You are a professional critical thinker. Use this context: {context} Question: {input}

query: "What abilities are needed for thinking critically?"
```

---

## ğŸ“˜ Data Source

The data used in `.txt` and `.pdf` files is sourced from the **Stanford Encyclopedia of Philosophy** article on *Critical Thinking*.
ğŸ”— [Source: SEP - Critical Thinking](https://plato.stanford.edu/entries/critical-thinking/#RequKnow)

All credit goes to SEP.

---

## ğŸ’¬ Sample Questions

* What abilities are needed for thinking critically?
* Explain is the process of critical thinking?
* Explain the role of dispositions in critical thinking.

---

## âš ï¸ Limitations

* No multi-turn chat history
* Only local Ollama-compatible models supported
* Limited data formats (no HTML/JSON yet)
* Not optimized for production environments

---

## ğŸ“ˆ Future Improvements

* Add chat memory/history
* Add support for JSON, HTML, and Wikipedia data loaders
* Support remote LLMs (e.g., OpenAI, Anthropic)

---

## ğŸ·ï¸ License / Acknowledgments

* ğŸ“š Content from SEP: [https://plato.stanford.edu/entries/critical-thinking](https://plato.stanford.edu/entries/critical-thinking)

---
